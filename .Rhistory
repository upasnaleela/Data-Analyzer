{
df<- do.call("rbind",lapply(twtList,as.data.frame))
#removes emoticons
df$text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
df$text = gsub("(f|ht)tp(s?)://(.*)[.][a-z]+", "", df$text)
return (df$text)
}
# Function to create a data frame from tweets
pos.words = scan('positive-words.txt', what='character', comment.char=';')
neg.words = scan('negative-words.txt', what='character', comment.char=';')
wordDatabase<-function()
{
pos.words<<-c(pos.words, 'Congrats', 'prizes', 'prize', 'thanks', 'thnx', 'Grt', 'gr8', 'plz', 'trending', 'recovering', 'brainstorm', 'leader', 'power', 'powerful', 'latest')
neg.words<<-c(neg.words, 'Fight', 'fighting', 'wtf', 'arrest', 'no', 'not')
}
score.sentiment <- function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)
sentence = gsub('\n','',sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp=sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1=c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new=lapply(list, `[[`, 1)
pp1=score=lapply(list, `[[`, 2)
nn1=score=lapply(list, `[[`, 3)
scores.df = data.frame(score=score_new, text=sentences)
positive.df = data.frame(Positive=pp1, text=sentences)
negative.df = data.frame(Negative=nn1, text=sentences)
list_df=list(scores.df, positive.df, negative.df)
return(list_df)
}
#TABLE DATA
library(reshape)
sentimentAnalyser<-function(result)
{
#Creating a copy of result data frame
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Positive=table2$value, Negative=table3$value, Score=table1$value)
return(table_final)
}
percentage<-function(table_final)
{
#Positive Percentage
#Renaming
posSc=table_final$Positive
negSc=table_final$Negative
#Adding column
table_final$PosPercent = posSc/ (posSc+negSc)
#Replacing Nan with zero
pp = table_final$PosPercent
pp[is.nan(pp)] <- 0
table_final$PosPercent = pp*100
#Negative Percentage
#Adding column
table_final$NegPercent = negSc/ (posSc+negSc)
#Replacing Nan with zero
nn = table_final$NegPercent
nn[is.nan(nn)] <- 0
table_final$NegPercent = nn*100
return(table_final)
}
wordDatabase()
twtList<-reactive({twtList<-searchTwitter(input$searchTerm, n=input$maxTweets, lang="en") })
tweets<-reactive({tweets<-TweetFrame(twtList() )})
result<-reactive({result<-score.sentiment(tweets(), pos.words, neg.words, .progress='none')})
table_final<-reactive({table_final<-sentimentAnalyser(  result() )})
table_final_percentage<-reactive({table_final_percentage<-percentage(  table_final() )})
output$tabledata<-renderTable(table_final_percentage())
#WORDCLOUD
wordclouds<-function(text)
{
library(tm)
library(wordcloud)
corpus <- Corpus(VectorSource(text))
#clean text
clean_text <- tm_map(corpus, removePunctuation)
#clean_text <- tm_map(clean_text, content_transformation)
clean_text <- tm_map(clean_text, content_transformer(tolower))
clean_text <- tm_map(clean_text, removeWords, stopwords("english"))
clean_text <- tm_map(clean_text, removeNumbers)
clean_text <- tm_map(clean_text, stripWhitespace)
return (clean_text)
}
text_word<-reactive({text_word<-wordclouds( tweets() )})
output$word <- renderPlot({ wordcloud(text_word(),random.order=F,max.words=80, col=rainbow(100), scale=c(4.5, 1)) })
#HISTOGRAM
output$histPos<- renderPlot({ hist(table_final()$Positive, col=rainbow(10), main="Histogram of Positive Sentiment", xlab = "Positive Score") })
output$histNeg<- renderPlot({ hist(table_final()$Negative, col=rainbow(10), main="Histogram of Negative Sentiment", xlab = "Negative Score") })
output$histScore<- renderPlot({ hist(table_final()$Score, col=rainbow(10), main="Histogram of Score Sentiment", xlab = "Overall Score") })
#Pie
slices <- reactive ({ slices <- c(sum(table_final()$Positive), sum(table_final()$Negative)) })
labels <- c("Positive", "Negative")
library(plotrix)
output$piechart <- renderPlot({ pie3D(slices(), labels = labels, col=rainbow(length(labels)),explode=0.00, main="Sentiment Analysis") })
#Top trending tweets
toptrends <- function(place)
{
a_trends = availableTrendLocations()
woeid = a_trends[which(a_trends$name==place),3]
trend = getTrends(woeid)
trends = trend[1:2]
dat <- cbind(trends$name)
dat2 <- unlist(strsplit(dat, split=", "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
return (dat4)
}
trend_table<-reactive({ trend_table<-toptrends(input$trendingTable) })
output$trendtable <- renderTable(trend_table())
#TOP TWEETERS
# Top tweeters for a particular hashtag (Barplot)
toptweeters<-function(tweetlist)
{
tweets <- twListToDF(tweetlist)
tweets <- unique(tweets)
# Make a table of the number of tweets per user
d <- as.data.frame(table(tweets$screenName))
d <- d[order(d$Freq, decreasing=T), ] #descending order of tweeters according to frequency of tweets
names(d) <- c("User","Tweets")
return (d)
}
# Plot the table above for the top 20
d<-reactive({d<-toptweeters(  twtList() ) })
output$tweetersplot<-renderPlot ( barplot(head(d()$Tweets, 20), names=head(d()$User, 20), horiz=F, las=2, main="Top Tweeters", col=1) )
output$tweeterstable<-renderTable(head(d(),20))
#TOP 10 HASHTAGS OF USER
tw1 <- reactive({ tw1 = userTimeline(input$user, n = 3200) })
tw <- reactive({ tw = twListToDF(tw1()) })
vec1<-reactive ({ vec1 = tw()$text })
extract.hashes = function(vec){
hash.pattern = "#[[:alpha:]]+"
have.hash = grep(x = vec, pattern = hash.pattern)
hash.matches = gregexpr(pattern = hash.pattern,
text = vec[have.hash])
extracted.hash = regmatches(x = vec[have.hash], m = hash.matches)
df = data.frame(table(tolower(unlist(extracted.hash))))
colnames(df) = c("tag","freq")
df = df[order(df$freq,decreasing = TRUE),]
return(df)
}
dat<-reactive({ dat = head(extract.hashes(vec1()),50) })
dat2<- reactive ({ dat2 = transform(dat(),tag = reorder(tag,freq)) })
p<- reactive ({ p = ggplot(dat2(), aes(x = tag, y = freq)) + geom_bar(stat="identity", fill = "blue")
p + coord_flip() + labs(title = "Hashtag frequencies in the tweets of the tweeter") })
output$tophashtagsplot <- renderPlot ({ p() })
}) #shiny server
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Twitter Sentiment Analysis"),
# Getting User Inputs
sidebarPanel(
textInput("searchTerm", "Enter data to be searched with '#'", "#"),
sliderInput("maxTweets","Number of recent tweets to use for analysis:",min=5,max=1000,value=500),
submitButton(text="Analyse")
),
mainPanel(
tabsetPanel(
tabPanel("Top Trending Tweets Today",HTML("<div>Top Trending Tweets according to location</div>"),
selectInput("trendingTable","Choose location to extract trending tweets",c("Mumbai","Delhi","Ahmedabad","Rajkot","Punjab"), selected = "Worldwide", selectize = FALSE),
submitButton(text="Search"),HTML("<div><h3> The table below shows the top trending
hashtags on Twitter of the location you have chosen. These are the hot topics today! </h3></div>"),
tableOutput("trendtable"),
HTML
("<div> </div>")),
tabPanel("WordCloud",HTML("<div><h3>Most used words associated with the hashtag</h3></div>"),plotOutput("word"),
HTML
("<div><h4> A word cloud is a visual representation of text data, typically used to depict keyword metadata (tags) on websites, or to visualize free form text.
This format is useful for quickly perceiving the most prominent terms and for locating a term alphabetically to determine its relative prominence.
</h4></div>")),
tabPanel("Histogram",HTML
("<div><h3> Histograms graphically depict the positivity or negativity of peoples' opinion about of the hashtag
</h3></div>"), plotOutput("histPos"), plotOutput("histNeg"), plotOutput("histScore")
),
tabPanel("Pie Chart",HTML("<div><h3>Pie Chart</h3></div>"), plotOutput("piechart"),HTML
("<div><h4> A pie chart is a circular statistical graphic, which is divided into slices to illustrate the sentiment of the hashtag. In a pie chart, the arc length
of each slice (and consequently its central angle and area), is proportional to the quantity it represents.</h4></div>")
),
tabPanel("Table",HTML( "<div><h3> Depicting sentiment in a tablular form on a scale of 5 </h3></div>"), tableOutput("tabledata"),
HTML ("<div><h4> The table depicts the sentiment (positive, negative or neutral) of the tweets
associated with the search hashtag by showing the score for each type of sentiment. </h4></div>")),
tabPanel("Top tweeters",HTML
("<div><h3> Top 20 tweeters of hastag</h3></div>"),plotOutput("tweetersplot"), tableOutput("tweeterstable")),
tabPanel("Top Hashtags of User",textInput("user", "Enter User Name", "@"),submitButton(text="Search"),plotOutput("tophashtagsplot"),HTML
("<div> <h3>Hastag frequencies in the tweets of the tweeter</h3></div>"))
)#end of tabset panel
)#end of main panel
))#end of shinyUI
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Twitter Sentiment Analysis"),
# Getting User Inputs
sidebarPanel(
textInput("searchTerm", "Enter data to be searched with '#'", "#"),
sliderInput("maxTweets","Number of recent tweets to use for analysis:",min=5,max=1000,value=500),
submitButton(text="Analyse")
),
mainPanel(
tabsetPanel(
tabPanel("Top Trending Tweets Today",HTML("<div>Top Trending Tweets according to location</div>"),
selectInput("trendingTable","Choose location to extract trending tweets",c("Mumbai","Delhi","Ahmedabad","Rajkot","Punjab"), selected = "Worldwide", selectize = FALSE),
submitButton(text="Search"),HTML("<div><h3> The table below shows the top trending
hashtags on Twitter of the location you have chosen. These are the hot topics today! </h3></div>"),
tableOutput("trendtable"),
HTML
("<div> </div>")),
tabPanel("WordCloud",HTML("<div><h3>Most used words associated with the hashtag</h3></div>"),plotOutput("word"),
HTML
("<div><h4> A word cloud is a visual representation of text data, typically used to depict keyword metadata (tags) on websites, or to visualize free form text.
This format is useful for quickly perceiving the most prominent terms and for locating a term alphabetically to determine its relative prominence.
</h4></div>")),
tabPanel("Histogram",HTML
("<div><h3> Histograms graphically depict the positivity or negativity of peoples' opinion about of the hashtag
</h3></div>"), plotOutput("histPos"), plotOutput("histNeg"), plotOutput("histScore")
),
tabPanel("Pie Chart",HTML("<div><h3>Pie Chart</h3></div>"), plotOutput("piechart"),HTML
("<div><h4> A pie chart is a circular statistical graphic, which is divided into slices to illustrate the sentiment of the hashtag. In a pie chart, the arc length
of each slice (and consequently its central angle and area), is proportional to the quantity it represents.</h4></div>")
),
tabPanel("Table",HTML( "<div><h3> Depicting sentiment in a tablular form on a scale of 5 </h3></div>"), tableOutput("tabledata"),
HTML ("<div><h4> The table depicts the sentiment (positive, negative or neutral) of the tweets
associated with the search hashtag by showing the score for each type of sentiment. </h4></div>")),
tabPanel("Top tweeters",HTML
("<div><h3> Top 20 tweeters of hastag</h3></div>"),plotOutput("tweetersplot"), tableOutput("tweeterstable")),
tabPanel("Top Hashtags of User",textInput("user", "Enter User Name", "@"),submitButton(text="Search"),plotOutput("tophashtagsplot"),HTML
("<div> <h3>Hastag frequencies in the tweets of the tweeter</h3></div>"))
)#end of tabset panel
)#end of main panel
))#end of shinyUI
library(twitteR)
library(stringr)
library(ROAuth)
library(RCurl)
library(ggplot2)
library(reshape)
library(tm)
library(RJSONIO)
library(wordcloud)
library(gridExtra)
library(plyr)
library(e1071)
library(RTextTools)
shinyServer(function(input, output) {
# Clean the tweets
TweetFrame<-function(twtList)
{
df<- do.call("rbind",lapply(twtList,as.data.frame))
#removes emoticons
df$text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
df$text = gsub("(f|ht)tp(s?)://(.*)[.][a-z]+", "", df$text)
return (df$text)
}
# Function to create a data frame from tweets
pos.words = scan('positive-words.txt', what='character', comment.char=';')
neg.words = scan('negative-words.txt', what='character', comment.char=';')
wordDatabase<-function()
{
pos.words<<-c(pos.words, 'Congrats', 'prizes', 'prize', 'thanks', 'thnx', 'Grt', 'gr8', 'plz', 'trending', 'recovering', 'brainstorm', 'leader', 'power', 'powerful', 'latest')
neg.words<<-c(neg.words, 'Fight', 'fighting', 'wtf', 'arrest', 'no', 'not')
}
score.sentiment <- function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)
sentence = gsub('\n','',sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp=sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1=c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new=lapply(list, `[[`, 1)
pp1=score=lapply(list, `[[`, 2)
nn1=score=lapply(list, `[[`, 3)
scores.df = data.frame(score=score_new, text=sentences)
positive.df = data.frame(Positive=pp1, text=sentences)
negative.df = data.frame(Negative=nn1, text=sentences)
list_df=list(scores.df, positive.df, negative.df)
return(list_df)
}
#TABLE DATA
library(reshape)
sentimentAnalyser<-function(result)
{
#Creating a copy of result data frame
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Positive=table2$value, Negative=table3$value, Score=table1$value)
return(table_final)
}
percentage<-function(table_final)
{
#Positive Percentage
#Renaming
posSc=table_final$Positive
negSc=table_final$Negative
#Adding column
table_final$PosPercent = posSc/ (posSc+negSc)
#Replacing Nan with zero
pp = table_final$PosPercent
pp[is.nan(pp)] <- 0
table_final$PosPercent = pp*100
#Negative Percentage
#Adding column
table_final$NegPercent = negSc/ (posSc+negSc)
#Replacing Nan with zero
nn = table_final$NegPercent
nn[is.nan(nn)] <- 0
table_final$NegPercent = nn*100
return(table_final)
}
wordDatabase()
twtList<-reactive({twtList<-searchTwitter(input$searchTerm, n=input$maxTweets, lang="en") })
tweets<-reactive({tweets<-TweetFrame(twtList() )})
result<-reactive({result<-score.sentiment(tweets(), pos.words, neg.words, .progress='none')})
table_final<-reactive({table_final<-sentimentAnalyser(  result() )})
table_final_percentage<-reactive({table_final_percentage<-percentage(  table_final() )})
output$tabledata<-renderTable(table_final_percentage())
#WORDCLOUD
wordclouds<-function(text)
{
library(tm)
library(wordcloud)
corpus <- Corpus(VectorSource(text))
#clean text
clean_text <- tm_map(corpus, removePunctuation)
#clean_text <- tm_map(clean_text, content_transformation)
clean_text <- tm_map(clean_text, content_transformer(tolower))
clean_text <- tm_map(clean_text, removeWords, stopwords("english"))
clean_text <- tm_map(clean_text, removeNumbers)
clean_text <- tm_map(clean_text, stripWhitespace)
return (clean_text)
}
text_word<-reactive({text_word<-wordclouds( tweets() )})
output$word <- renderPlot({ wordcloud(text_word(),random.order=F,max.words=80, col=rainbow(100), scale=c(4.5, 1)) })
#HISTOGRAM
output$histPos<- renderPlot({ hist(table_final()$Positive, col=rainbow(10), main="Histogram of Positive Sentiment", xlab = "Positive Score") })
output$histNeg<- renderPlot({ hist(table_final()$Negative, col=rainbow(10), main="Histogram of Negative Sentiment", xlab = "Negative Score") })
output$histScore<- renderPlot({ hist(table_final()$Score, col=rainbow(10), main="Histogram of Score Sentiment", xlab = "Overall Score") })
#Pie
slices <- reactive ({ slices <- c(sum(table_final()$Positive), sum(table_final()$Negative)) })
labels <- c("Positive", "Negative")
library(plotrix)
output$piechart <- renderPlot({ pie3D(slices(), labels = labels, col=rainbow(length(labels)),explode=0.00, main="Sentiment Analysis") })
#Top trending tweets
toptrends <- function(place)
{
a_trends = availableTrendLocations()
woeid = a_trends[which(a_trends$name==place),3]
trend = getTrends(woeid)
trends = trend[1:2]
dat <- cbind(trends$name)
dat2 <- unlist(strsplit(dat, split=", "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
return (dat4)
}
trend_table<-reactive({ trend_table<-toptrends(input$trendingTable) })
output$trendtable <- renderTable(trend_table())
#TOP TWEETERS
# Top tweeters for a particular hashtag (Barplot)
toptweeters<-function(tweetlist)
{
tweets <- twListToDF(tweetlist)
tweets <- unique(tweets)
# Make a table of the number of tweets per user
d <- as.data.frame(table(tweets$screenName))
d <- d[order(d$Freq, decreasing=T), ] #descending order of tweeters according to frequency of tweets
names(d) <- c("User","Tweets")
return (d)
}
# Plot the table above for the top 20
d<-reactive({d<-toptweeters(  twtList() ) })
output$tweetersplot<-renderPlot ( barplot(head(d()$Tweets, 20), names=head(d()$User, 20), horiz=F, las=2, main="Top Tweeters", col=1) )
output$tweeterstable<-renderTable(head(d(),20))
#TOP 10 HASHTAGS OF USER
tw1 <- reactive({ tw1 = userTimeline(input$user, n = 3200) })
tw <- reactive({ tw = twListToDF(tw1()) })
vec1<-reactive ({ vec1 = tw()$text })
extract.hashes = function(vec){
hash.pattern = "#[[:alpha:]]+"
have.hash = grep(x = vec, pattern = hash.pattern)
hash.matches = gregexpr(pattern = hash.pattern,
text = vec[have.hash])
extracted.hash = regmatches(x = vec[have.hash], m = hash.matches)
df = data.frame(table(tolower(unlist(extracted.hash))))
colnames(df) = c("tag","freq")
df = df[order(df$freq,decreasing = TRUE),]
return(df)
}
dat<-reactive({ dat = head(extract.hashes(vec1()),50) })
dat2<- reactive ({ dat2 = transform(dat(),tag = reorder(tag,freq)) })
p<- reactive ({ p = ggplot(dat2(), aes(x = tag, y = freq)) + geom_bar(stat="identity", fill = "blue")
p + coord_flip() + labs(title = "Hashtag frequencies in the tweets of the tweeter") })
output$tophashtagsplot <- renderPlot ({ p() })
}) #shiny server
runApp("TWITTER ANALYXIS")
library(twitteR)
library(stringr)
library(ROAuth)
library(RCurl)
library(ggplot2)
library(reshape)
library(tm)
library(RJSONIO)
library(wordcloud)
library(gridExtra)
library(plyr)
library(e1071)
library(RTextTools)
install.packages(RCurl)
install.package(RCurl)
install.package("RCurl")
install.packages("RCurl")
library(RCurl)
library("RCurl")
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
runApp(TWITTER ANALYXIS)
runApp("TWITTER ANALYXIS")
q()
setwd("D:\STUDY\BE\FINAL YEAR PROJECT\7TH SEM\IMPLEMENTATION\DATA ANALYZER\TWITTER\TWITTER ANALYSIS")
setwd("D:/STUDY/BE/FINAL YEAR PROJECT/7TH SEM/IMPLEMENTATION/DATA ANALYZER/TWITTER/TWITTER ANALYSIS")
runApp("TWITTER ANALYSIS")
runapplibrary(twitteR)
library(ROAuth)
consumer_key<-"sI8ufoxHnhdb28ouN0IhC5HW1"
consumer_secret<-"HlVd8YYSexUDJs9hWtZc8KujMZN2DlT4HO2hMYPIUDLnQFvCVY"
accesstoken<-"3367472419-cuMifl7YfG43DW5x9YCNtTMLz7p90for2ZO6h3A"
accesssecret<-"SpC5G34eGYRMF5wyDMx1uM630R4zfSM0dGPod0C19XsuZ"
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
setup_twitter_oauth(consumer_key,consumer_secret,accesstoken,accesssecret)
cred <- OAuthFactory$new(consumerKey=consumer_key,
consumerSecret=consumer_secret,
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
cred$handshake(cainfo="cacert.pem")
5226118
runApp("TWITTER ANALYSIS")
q()
shiny::runApp()
